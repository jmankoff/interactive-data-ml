{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Byte 4: Machine Learning\n",
    "In this byte you will use machine learning to understand a data set. We will explore the differences in demographics data between males and females. Your goal is to use a combination of exploratory analysis and machine learning to train a model that best predicts the sex of a person (as defined in the US census data) based on their demographics data collected in an anual US census dataset. You will discuss the implications of being able to predict a person's sex and what that means in terms of differences between the sexes (including any biases and discriminations). We will feature models that best predict the sexes in class.\n",
    "\n",
    "This assignment has two difficulties:\n",
    "\n",
    "1. begginer, in which you will simply execute the provided code, make small, guided modifications, and interpret the results\n",
    "2. intermediate to expert, in which you will independently modify the code to add and optimize an algorithm of your choosing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Configure Required Libraries\n",
    "We begin by importing libraries you will use in this byte. We will use Pandas to pre-process and clean the data, Seaborn to visualize the data and perform exploratory analysis, and scikit learn (a Python ML library) to train a model that predicts the sex of a person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Discritizes columns. Note it changes the order of columns.\n",
    "def digitize(x, bins=[], cols=[]):\n",
    "    mask = np.ones(x.shape[1], np.bool)\n",
    "    mask[cols] = 0\n",
    "    \n",
    "    return np.hstack((np.apply_along_axis(np.digitize, 1, x[:,cols], bins=bins), x[:,mask]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: American Community Survey 2015\n",
    "In this byte we will use data from the 2015 American Community Survey which includes random sample of 3 million people that live in the US. You can find detailed information about the dataset in data/ACS2015_PUMS_README.pdf and a complete data dictionary in data/PUMSDataDict15.txt. We combined the data from the housing and personal files for you, so that each record in the files contains a person record together with their housing record. We also included only persons ages 18 and up. Also note that we have removed some of the variables from the data set.\n",
    "\n",
    "In this assignent you will experience a machine learning method for selecting and optimizing an algorithm that prevents overfitting and biasing your algorithm on your training data. This helps improve the ability of your model to predict unseen data.\n",
    "\n",
    "This methodology calls for spliting the data into three different datasets:\n",
    "\n",
    "1. dev (10% of the data) - development data set we use for exploratory analysis, feature selection, and algorithm selection and optimization,\n",
    "2. train (60% of the data) - training data set we use for training our optimized algorithm, and\n",
    "3. test (30% of the data) - test data set for estimating the final algorithm performance.\n",
    "\n",
    "At the end of this process you would combine all three datasets back into a single dataset and train your final model on the whole data.\n",
    "\n",
    "We already split the data for you, although this can easily be done by loading the whole dataset into a Pandas dataframe and using scikit-learn to split it into different parts using the train_test_split() function from the sklearn.model_selection package. The files are:\n",
    "\n",
    "* data/data.csv.zip - whole dataset\n",
    "* data/dev.csv.zip - development set\n",
    "* data/train.csv.zip - training set\n",
    "* data/test.csv.zip - testing set\n",
    "\n",
    "Note that we have also taken a part of the original data out that you will not have access to. This holdout set will simulate unseen data for you and we will use it to test your final algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis and Feature Selection\n",
    "In this section you will use the development set to explore the data and select your features using a combination of your intuition and statistical methods. Then you will perform a preliminary algorithm selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by loading the development set from the data directory. Note that the file is compressed, comma separated values file. We load it into a Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dev = pd.read_csv('../data/dev.csv.zip', compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, read the two documents describing the dataset (data/ACS2015_PUMS_README.pdf and data/PUMSDataDict15.txt) and get familiar with the different variables. You can use Seaborn to visualize the data. For example, you can start with comparing the number of records in the two classes that we will try to predict (1-MALE, 2-FEMALE). Although SEX contains numerical values, it is categorical. Thus, it is important to treat it as such.\n",
    "\n",
    "<strong>In classification, the class variable is always cathegorical!</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.countplot(x=\"SEX\", data=dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The count plot above shows that the two classes are fairly balanced. This is good because when classes are NOT balanced, we have to make special considerations when training our algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering and Selection\n",
    "Next, we look for features that might be predictive of the two sexes. Often real world datasets are not clean and require a good understanding of the data before we can apply a machine learning algorithm. Also, data often contains features that are in a format that is not predictive of the class. In such cases training an algorithm on the features without any changes of modification will produce bismal results and the automated feature selection algorithms will not work (if you are in the intermediate to expert stream, we invite you to try to do something like that on this dataset and see what happens).\n",
    "\n",
    "That is why in this byte we approach this the classification as a feature engineering problem. Here we will explore the data set first and use our intuition, assumptions, and existing knowledge to select a few features that will hopefully help us in the prediction task.\n",
    "\n",
    "We start off by looking at personal income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Personal Income (PINCP)\n",
    "We begin by exploring the personal income feature. We hypothesize that females will have lower income than males because of the wage inequality (https://en.wikipedia.org/wiki/Gender_pay_gap_in_the_United_States).\n",
    "\n",
    "Dataset documentation tells us that the feature contains NaN values, but that those values mean that the person is 15 years or younger. That means that the child had no income (the parent or guardian would get the income in this case). That is fine in our case because we only conisder adults, ages 18 and up.\n",
    "\n",
    "We still impute any possible missing values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dev.loc[dev['PINCP'].isnull(),'PINCP'] = 0\n",
    "dev.loc[dev['WAGP'].isnull(),'WAGP'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then compare the distribution of personal income across the two classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=dev, x='SEX', y='PINCP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the distribution of wage income across the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=dev, x='SEX', y='WAGP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The boxplots shows that there is likely a difference in personal income and wages between the two classes (despite large number of ourliers). We also note that the data is likely not normally distributed, which will come into play later. However, there also does not seem to be a clear (linear) separation between the two classes.\n",
    "\n",
    "We pause our exploration of personal income to take a look at other features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age\n",
    "We look at age because we noted that we will have difficulty classifying children ages 15 and below, so we should probably consider age in our model somehow.\n",
    "\n",
    "We note and confirm that there should be no missing values, and plot our data again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(dev[dev['AGEP'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=dev, x='SEX', y='AGEP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eyeballing the data, we do not see any major differences between the two sexes. Also, note that although there are differences in the life expectency between the two sexes (https://en.wikipedia.org/wiki/List_of_countries_by_life_expectancy), the data reffers to the person's current age, and not their projected life expectancy. We choose not to include age as it is right now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Marital Status\n",
    "The age discussion above brings up an interesting point: females have higher life expectancy. Thus, we would expect that there would be more widowed females than males. Thus, we search the dataset for a feature that indicates if a person is widowed or not: marital status.\n",
    "\n",
    "However, unlike the previous two features, this feature is categorical although in the data set it is encoded as a number. <strong>You always have to ensure that features have the right type!</strong>\n",
    "\n",
    "Because it is categorical, we use count plot to look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(dev[dev['MAR'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.countplot(data=dev, x='MAR', hue='SEX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eyeballing the data, it looks like we are correct. However, this feature will only help in a small number of cases when a person is widowed. What else can you see in this chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Occupation\n",
    "Gender differences in occupational distribution among workers persist even if they are volountary choices (https://www.bls.gov/opub/mlr/2007/06/art2full.pdf). Thus, we explore each person's occupation as a potential feature.\n",
    "\n",
    "However, not only is this feature categorical, documentation reveals that there is also a large number of possible values for this feature. This often significantly degrades machine learning algorithm performance because there is usually not enough examples for each value to make accurate inference. Thus, we reduce the number of possible values based on the occupation code (i.e., we only consider the first two digits).\n",
    "\n",
    "We preserve the old feature for reference, and add a new one. We first convert all values that are not null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dev['SCOP_REDUCED'] = pd.to_numeric(dev[dev['SOCP'].notnull()]['SOCP'].str.slice(start=0, stop=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we preserve the special value of NaN in this case (less than 16 years old or never worked) and assign it to a special code '00':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dev.loc[dev['SCOP_REDUCED'].isnull(), 'SCOP_REDUCED'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now look at the difference in occupation across sexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.countplot(data=dev, x='SCOP_REDUCED', hue='SEX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are still differences between occupation categories between the two sexes (e.g., construction '47' is still dominated by males, but education and administrative is dominated by females)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Revisiting Wage Gap\n",
    "Now we are ready to look at the wage gap again. Our goal is to capture the wage gap (if it exists). We consider three different ways to do this:\n",
    "\n",
    "1. We could look at the income proportion of the person compared to the total family income.\n",
    "2. We can compare how far the person's income is from the median or mean salary of males and females.\n",
    "3. We can compare how far the person's income is from the median or mean salary of males and females in their occupation.\n",
    "\n",
    "Option 1 may not work well for single parent, and option 2 may not capture the differences between salaries in different occupation fields. Think about other cases in which these features will fail to convey the wage gap.\n",
    "\n",
    "We choose option 3, and take a look at the wage gap across different occupations.\n",
    "\n",
    "We first compate personal income:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.factorplot(data=dev[['SCOP_REDUCED', 'SEX', 'PINCP']], x='SCOP_REDUCED', y='PINCP', hue='SEX', kind='box', size=7, aspect=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Followed by wages (note the difference between wages and total income):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.factorplot(data=dev[['SCOP_REDUCED', 'SEX', 'WAGP']], x='SCOP_REDUCED', y='WAGP', hue='SEX', kind='box', size=7, aspect=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eyeballing the results, we can conclude that females are on average paid less than males across different occupation fields. Here we decide to include the income and wage features as they are and let the model decide the differences between the classes.\n",
    "\n",
    "<strong>If you are in the intermediate/expert stream:</strong> consider making another feature that makes the gap explicit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your Features\n",
    "<em>If you are in the intermediate to expert stream, this is where you would explore your own features that could potentially improve the classification performance. Use the examples above to come up with new features. You can reuse some of the features above or completely discard them.</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Summary\n",
    "Here we finalize a list of features we created and/or selected in the previous step. Below is a list of features we will use. Remember to add your own features if you selected and/or created any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modify this cell to add more features if any.\n",
    "select_features = ['PINCP', 'WAGP', 'MAR', 'SCOP_REDUCED']\n",
    "categorical_features = ['MAR', 'SCOP_REDUCED']\n",
    "\n",
    "# Used for specifying which features to bin in $20,000 increments.\n",
    "# Note that if you have features you would like to bin in a custom way, then you will have to modify the Naive Bayes\n",
    "# classifier below.\n",
    "monetary_features = ['PINCP', 'WAGP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create a new dev data frame containing only the selected features and the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "select_dev = dev[select_features + ['SEX']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions you need to answer:\n",
    "<strong>Both paths:</strong> <em>Summarize your findings about different features you selected, including insights about why they should help you predict/classify males and females.</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Algorithm Selection and Optimization\n",
    "In this section we will use the features we selected above to train and evaluate different machine leaning algorithms. Often it is not immediately clear which algorithm will perform the best on the dataset. Even if we are certain that an algorithm will do well, we need to compare it with a baseline algorithm (e.g., Zero R, which always selects the majority class) to make sure that we are improving on the status quo.\n",
    "\n",
    "We will compare a few algorithms to find out which one is most promissing. We perform this selection on the development set so that we do not overfit on the training data (which would have effects on the performance of the lagorithm on unseen data). Because our development set is comparably small, we will use cross-validation to evaluate our algorithms. However, because we also want to optimize the algorithms we are comparing (to ensure we are selecting the best configuration) we will use what we call inner-outer 10 fold cross validation.\n",
    "\n",
    "In the inner fold we will optimize an algorithm and pick the best optimization, and in the outerfold we will compare the best opimized algorithms.\n",
    "\n",
    "In most cases we desire an algorithm with a high accuracy as a score. This metric is a decent indicator of performance when classifying balanced classes (as is our case). However, sometimes it is even more important to consider the impact of errors on the performance (precision and recall) and the general quality of the fit (kappa statistic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by defining a set of algorithms that we will compare. We chose 3 algorithms:\n",
    "\n",
    "1. Zero R, which always picks the majority class. This is our baseline.\n",
    "2. Naive Bayes, which is a fast algorithm based on the Bayes' theorem, but with a naive assumptions about independence of features given the class (http://scikit-learn.org/stable/modules/naive_bayes.html)\n",
    "3. Decision Tree, which is a non-parametric supervised learning method used for classification that predicts the value of a target variable by learning simple decision rules inferred from the data features (copied from http://scikit-learn.org/stable/modules/tree.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>If you are in the intermediate/expert path you need to pick your own algorithm to add to the race!</strong> If you are unsure where to start, you can use this chart to help you pick an algorithm: http://scikit-learn.org/stable/tutorial/machine_learning_map/. Then add specifications for your algorithm below (use the existing examples on how to create your own pipeline for the algorithm):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifiers = {}\n",
    "classifier_parameters = {}\n",
    "\n",
    "# Zero R\n",
    "# This classifier does not require any additional preprocessing of data.\n",
    "classifiers['ZeroR'] = DummyClassifier(strategy='prior')\n",
    "\n",
    "# Binomial NB classifier\n",
    "# This classifier requires that all features are in binary form.\n",
    "# We can easily transform categorical data into binary form, but we have to first disretize continius variables first.\n",
    "classifiers['Naive Bayes'] = Pipeline([\n",
    "    ('discretize', FunctionTransformer(func=digitize, kw_args={'bins':np.array([0.0, 20000.0, 40000.0, 80000.0, 100000.0]), 'cols':pd.Series(select_features).isin(monetary_features)})), \n",
    "    ('tranform', OneHotEncoder(categorical_features='all')), \n",
    "    ('clf', BernoulliNB())])\n",
    "\n",
    "# Decision Tree classifier\n",
    "# This classifier can work on continious features and can find a good separation point on its own.\n",
    "# We still have to convert categorical data to binary format.\n",
    "classifiers['Decision Tree'] = Pipeline([('tranform', OneHotEncoder(categorical_features=pd.Series(select_features).isin(categorical_features))), ('clf', DecisionTreeClassifier())])\n",
    "\n",
    "# Maximum Depth for a decision tree controls how many levels deep the tree will go before it stops.\n",
    "# More levels means less generalizability, but fewer levels means less predictive power.\n",
    "classifier_parameters['Decision Tree'] = {'clf__max_depth':(1, 3, 9, 12)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepare out development set by creating 10 folds we will use to evaluate the algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now iterate over the classifiers and report the metrics for all of them. Sklearn offers a number of functions to quickly score results of a cross validation, but we would like to make sure that all of the algorightms run on the same folds. So we quickly code our own experiment below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a label encoder to transform 1-MALE, 2-FEMALE into classes that sklearn can use (0 and 1).\n",
    "le = LabelEncoder() \n",
    "\n",
    "# Split features and class into two dataframes.\n",
    "X_dev = select_dev.ix[:, select_dev.columns != 'SEX'].values\n",
    "y_dev = le.fit_transform(select_dev['SEX'].values)\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# Initialize scores dict\n",
    "scores = pd.DataFrame(columns=['fold', 'algorithm', 'parameters', 'accuracy'])\n",
    "\n",
    "# For each fold run the classifier (outer CV).\n",
    "fold = 0\n",
    "for train_index, test_index in kf.split(X_dev):\n",
    "    X_train, X_test = X_dev[train_index], X_dev[test_index]\n",
    "    y_train, y_test = y_dev[train_index], y_dev[test_index]\n",
    "    \n",
    "    fold = fold + 1\n",
    "\n",
    "    # Iterate over classifiers\n",
    "    for name, clf in classifiers.items():\n",
    "        # If the classifier has parameters, then run inner CV.\n",
    "        # Luckily sklearn provides a quick method to do this.\n",
    "        if name in classifier_parameters:\n",
    "            gs = GridSearchCV(estimator=clf, param_grid=classifier_parameters[name])\n",
    "            gs.fit(X_train, y_train)\n",
    "            y_pred = gs.predict(X_test)\n",
    "            best_params = str(gs.best_params_)\n",
    "        else:\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            best_params = 'default'\n",
    "        \n",
    "        scores = scores.append(pd.DataFrame(data={'fold':[fold],'algorithm':[name], 'parameters':[best_params], 'accuracy':[accuracy_score(y_test, y_pred)]}), ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the Best Algorithm\n",
    "Here we analyse the results of our experiment and compare the algorithm scores to find the best algorithm. The sumary and box plot below shows the accuracy of the best algorithms in the outer fold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores[['algorithm', 'accuracy']].groupby(['algorithm']).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=scores, x='algorithm', y='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running Statistical Tests\n",
    "We now run a statistical test on the accuracies across different algorithms to ensure that the results above did not happen by chance. We ensured that we trained and evalueted all of the algorithms on the same outer folds, which means that we need to run a pairwise comparison. Also, although eyeballing the boxplot above we could assume that the accuracies came from normal distribution, we know that accuracy is takes value on an interval from [0,1] so we choose a non-parametric test instead (Friedman test, https://en.wikipedia.org/wiki/Friedman_test). We will perform post-hoc pairwise comparison using a Wilcoxon test.\n",
    "\n",
    "Our null-hypothesis is that there is no difference between the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matrix = scores.pivot(index='fold', columns='algorithm', values='accuracy').as_matrix()\n",
    "stats.friedmanchisquare(matrix[:,0], matrix[:,1], matrix[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(np.shape(matrix)[1]):\n",
    "    for j in range(i+1, np.shape(matrix)[1]):\n",
    "        print(stats.wilcoxon(matrix[:,i], matrix[:,j], correction=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results suggest that the Decision Tree was the best, but the accuraccy is still pretty low (despite a significant increase from the baseline)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree classifier is unique in a sense that it is easy to visualize the decisions that it is making. Here we look at the top 3 levels of the best algorithm we trained on the whole development set (if you have graph viz installed on your machine):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = select_dev.columns.tolist()\n",
    "features = features[1:len(features)-1]\n",
    "\n",
    "le = LabelEncoder() \n",
    "\n",
    "# Split features and class into two dataframes.\n",
    "X_dev = select_dev.ix[:, select_dev.columns != 'SEX']\n",
    "y_dev = le.fit_transform(select_dev['SEX'].values)\n",
    "\n",
    "X_dev_long = pd.get_dummies(data=X_dev, columns=categorical_features)\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=3)\n",
    "clf.fit(X_dev_long, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(clf,\n",
    "                           out_file=None,\n",
    "                           feature_names=X_dev_long.columns,\n",
    "                           class_names=['male', 'female'],  \n",
    "                           filled=True, rounded=True,  \n",
    "                           special_characters=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "Image(graph.create_png())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions you need to answer:\n",
    "What do the results of the tests mean? What can we conclude from the analysis? Is the best algorithm making reasnoble decisions? What kind of errors is the best algorithm making and can we improve somehow?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Machine Learning Algorithm\n",
    "In this section, we will use the insights from our exploratory analysis and optimization to train and test our final algorithm. As an illustration, we will use a DecisionTreeClassifier with maximum depth of 12 because this algorithm performed the best in the development phase. We are going to use the training data set to train the algorithm and the test data set to test it. In this phase we should have enough data to accurately estimate the performance of the algorithm, so we do not need to use cross validation.\n",
    "\n",
    "<strong>If you are in the intermediate/expert stream: </strong> if you changed or added any features of if your algorithm performed the best in the development stage, then make sure you make appropriate changes to both the features and algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "Here we load and pre-process the data in exactly the same way as we did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv.zip', compression='zip')\n",
    "test = pd.read_csv('../data/test.csv.zip', compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Marriage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ensure there is no NaN values.\n",
    "print(len(train[train['MAR'].isnull()]))\n",
    "print(len(test[test['MAR'].isnull()]))\n",
    "sns.countplot(data=train, x='MAR', hue='SEX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reduce and make sure no NaN.\n",
    "train['SCOP_REDUCED'] = pd.to_numeric(train[train['SOCP'].notnull()]['SOCP'].str.slice(start=0, stop=2))\n",
    "train.loc[train['SCOP_REDUCED'].isnull(), 'SCOP_REDUCED'] = 0\n",
    "test['SCOP_REDUCED'] = pd.to_numeric(test[test['SOCP'].notnull()]['SOCP'].str.slice(start=0, stop=2))\n",
    "test.loc[test['SCOP_REDUCED'].isnull(), 'SCOP_REDUCED'] = 0\n",
    "sns.countplot(data=train, x='SCOP_REDUCED', hue='SEX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Income and Wages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.loc[train['PINCP'].isnull(),'PINCP'] = 0\n",
    "train.loc[train['WAGP'].isnull(),'WAGP'] = 0\n",
    "test.loc[test['PINCP'].isnull(),'PINCP'] = 0\n",
    "test.loc[test['WAGP'].isnull(),'WAGP'] = 0\n",
    "sns.factorplot(data=train[['SCOP_REDUCED', 'SEX', 'WAGP']], x='SCOP_REDUCED', y='WAGP', hue='SEX', kind='box', size=7, aspect=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Best Algorithm\n",
    "Now we train the best algorithm using the training data set (the pre-processed features) and the specifications about the best algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "select_train = train[select_features + ['SEX']]\n",
    "select_test = test[select_features + ['SEX']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same pipeline as we did in the development stage, except that we only use one set of parameters (in this case max_depth=12). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Decision Tree classifier\n",
    "# This classifier can work on continious features and can find a good separation point on its own.\n",
    "# We still have to convert categorical data to binary format.\n",
    "best_clf = Pipeline([('tranform', OneHotEncoder(categorical_features=pd.Series(select_features).isin(categorical_features))), ('clf', DecisionTreeClassifier(max_depth=12))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split features and class into two dataframes.\n",
    "X_train = select_train.ix[:, select_train.columns != 'SEX'].values\n",
    "y_train = le.fit_transform(select_train['SEX'].values)\n",
    "\n",
    "X_test = select_test.ix[:, select_test.columns != 'SEX'].values\n",
    "y_test = le.fit_transform(select_test['SEX'].values)\n",
    "\n",
    "best_clf.fit(X_train, y_train)\n",
    "y_pred = best_clf.predict(X_test)\n",
    "y_score = best_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Best Algorithm\n",
    "We now calculate a series of statistics that allow us to gauge how well the algorithm will perform on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Accuracy: ' + str(metrics.accuracy_score(y_test, y_pred)))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve\n",
    "Now we plot the ROC curve that tells us how well our algorithm detected true positives vs. false positives (from http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_score[:,1])\n",
    "roc_auc = metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any curve above the blue line means that the algorithm is predicting better than by random chance. However, we would ideally like to have the orange curve as close as possible to the y-axis and ROC curve area to be in the .90's.\n",
    "\n",
    "<strong>Intermediate/expert stream:</strong> has your algorithm reached these statistics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision/Recall Curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "precision, recall, thresholds = metrics.precision_recall_curve(y_test, y_score[:,1])\n",
    "plt.clf()\n",
    "plt.plot(recall, precision, label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Precision/Recall Curve is not impressive either. Ideally, a rule of thumb tells us that a good model would have a curve that crosses (Precision, Recall) at (90, 80).\n",
    "\n",
    "<strong>Intermediate/expert stream:</strong> can you design a model that has such high performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now take a quick glance at the errors and if there is anything else we could have done better in hindsight. The code below selects all records where the algorithm awas wrond on the test set. What insights can you make from that? (hint: use the same feature visualization techniques we used when selecting features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_wrong = test[y_pred != y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the example below shows the distribution of different values of marriage feature ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.countplot(data=test_wrong, x='MAR', hue='SEX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions you need to answer:\n",
    "<strong>Both streams:</strong> Discuss the performance of the best algorithm and how you think it can be further improved. What kind of errors is the algorithm still making?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
